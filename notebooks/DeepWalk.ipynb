{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Classification and Link Prediction with DeepWalk\n",
    "\n",
    "Using DeepWalk for unsupervised node representation learning that can subsequently be used for supervised node classification and link prediction.\n",
    "\n",
    "#### References\n",
    "\n",
    "\\[1\\] [Deepwalk: Online learning for social representations](https://www.thejournal.club/c/paper/54593/), B. Perozzi, R. AlRfou, S. Skiena, KDD, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset (Cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to perform a random walk starting from each node in the graph.\n",
    "\n",
    "DGL has a method for generating random walk data, `dgl.sampling.random_walk(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.nodes()\n",
    "num_repeats = 10\n",
    "length = 20       # Random walk length\n",
    "doc = []\n",
    "for _ in range(num_repeats):\n",
    "    sentences, _ = dgl.sampling.random_walk(graph, nodes=nodes, length=length)\n",
    "    doc.extend(sentences.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph has 2708 nodes so the number of \"sentences\" should equal `num_repeats` times 2708."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use `gensim`'s implementation of `Word2Vec`.\n",
    "\n",
    "We are going to set the dimnsionality of the embedding vectors to __128__ and the window size to __5__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(doc, vector_size=128, window=5, min_count=0, sg=1, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the embedding vector for each node by using the node ID. Note that node IDs are integers from 0 to 2707."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes()  # the node IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrience the embedding vectors via the `wv` member variable of the `Word2Vec` models using the node ID as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(w2v_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = graph.ndata[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store node vectors in a 2D numpy array. We make sure that the row index correspond to the node ID.\n",
    "word_vectors = []\n",
    "for node in nodes:\n",
    "    word_vectors.append(w2v_model.wv[node.item()])\n",
    "word_vectors = np.array(word_vectors)\n",
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = TSNE(n_components=2)\n",
    "node_embeddings_2d = transform.fit_transform(word_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(node_embeddings, node_labels, title, x_label=\"$X_1$\", y_label=\"$X_2\", alpha=0.7, figsize=(7,7)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.scatter(node_embeddings[:, 0], \n",
    "               node_embeddings[:, 1], \n",
    "               c=node_labels, \n",
    "               cmap=\"jet\", alpha=alpha)\n",
    "    ax.set(aspect=\"equal\", xlabel=x_label, ylabel=y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(node_embeddings_2d, \n",
    "                graph.ndata['label'], \n",
    "                title='DeepWalk node embeddings for cora dataset', \n",
    "                x_label=\"$X_1$\", \n",
    "                y_label=\"$X_2$\", \n",
    "                alpha=0.7, \n",
    "                figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a node classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = word_vectors\n",
    "y = graph.ndata[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[graph.ndata[\"train_mask\"]]\n",
    "y_train = y[graph.ndata[\"train_mask\"]]\n",
    "X_test = X[graph.ndata[\"test_mask\"]]\n",
    "y_test = y[graph.ndata[\"test_mask\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=2, n_jobs=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = rf.score(X_train, y_train)\n",
    "test_acc = rf.score(X_test, y_test)\n",
    "print(f\"Train acc: {train_acc:.2} and Test acc: {test_acc:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "[Node2Vec](https://www.thejournal.club/c/paper/97424/) improves on DeepWalk by using biased random walks. It has 2 parameters that control how likely the random walker is to return back to the previous node or follow and edge further away. Carefully selecting these parameters allows the practitioner to calculate node embeddings that emphasize either node homophily or structural equivalance.\n",
    "\n",
    "A further extension to heterogeneous graphs is [MetaPath2Vec](https://www.thejournal.club/c/paper/290795/). It works the same as DeepWalk but the random walker is guided by a metapath (a valid sequence of node types) such that the node to follow is only allowed to be of the type specified in the metapath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "\\[1\\] Can you improve the results? Some ideas are to generate more random walk data with longer or shorter walk lengths. Tune the [**Word2Vec**](https://www.thejournal.club/c/paper/47668/) hyper-parameters, e.g., different window size, differenet embeddings dimensionality.\n",
    "\\[2\\] Implement biased random walks as proposed in **Node2Vec**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction\n",
    "\n",
    "For link prediction we need to estimate embedding vectors for edges. We are going to combine the node embeddings at the two ends of an edge into an edge vector. Once we have these edge vectors, we can train a binary classifier to predict if an edge between two nodes should exist or not.\n",
    "\n",
    "Before we can do the above, we must split remove some of the edges from the graph and keep them to the side for training and evaluating the performance of the binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the graph edges returned as tuple of 2 tensor such that the first holds the source node and the second\n",
    "# the target node for each edge\n",
    "all_edges = graph.edges()   \n",
    "all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_edges = int(len(all_edges[0]) * 0.1)   # use 10% of edges as positive examples for training\n",
    "print(f\"Number of positive examples in train set: {num_train_edges}\")\n",
    "# Randomly select num_test_edges out of edges\n",
    "edge_index = np.random.randint(0, len(all_edges[0]), size=num_train_edges)\n",
    "edges = (all_edges[0][edge_index], all_edges[1][edge_index])\n",
    "edge_labels = torch.ones(num_train_edges, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the edge IDs so we can remove them from the graph later\n",
    "eids = graph.edge_ids(edges[0], edges[1])\n",
    "eids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample negative examples, that is find pairs of nodes that are not connected by an edge\n",
    "source_nodes_candidate = nodes[torch.randperm(num_train_edges)]\n",
    "target_nodes_candidate = nodes[torch.randperm(num_train_edges)]\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "count = 0\n",
    "for s, t in zip(source_nodes_candidate, target_nodes_candidate):\n",
    "    if not graph.has_edges_between(s, t):\n",
    "        source_nodes.append(s.item())\n",
    "        target_nodes.append(t.item())\n",
    "        count += 1\n",
    "    if count == num_train_edges:\n",
    "        break\n",
    "        \n",
    "len(source_nodes), len(target_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = (torch.cat((edges[0], torch.tensor(source_nodes))),torch.cat((edges[1], torch.tensor(target_nodes)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels = torch.cat((edge_labels, torch.zeros(len(source_nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_labels), len(edges[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove the edges from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"graph num edges before: {graph.number_of_edges()}\")\n",
    "graph.remove_edges(eids)\n",
    "print(f\"graph num edges after: {graph.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the graph is different, let us re-calculate the node representations using DeepWalk. This is the same procedure we used earlier for unsupervised node representation learning that was subsequently used for node classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.nodes()\n",
    "num_repeats = 10\n",
    "length = 20       # Random walk length\n",
    "doc = []\n",
    "for _ in range(num_repeats):\n",
    "    sentences, _ = dgl.sampling.random_walk(graph, nodes=nodes, length=length)\n",
    "    doc.extend(sentences.tolist())\n",
    "\n",
    "w2v_model = Word2Vec(doc, vector_size=128, window=5, min_count=0, sg=1, workers=2)\n",
    "\n",
    "# Store node vectors in a 2D numpy array. We make sure that the row index correspond to the node ID.\n",
    "node_vectors = []\n",
    "for node in nodes:\n",
    "    node_vectors.append(w2v_model.wv[node.item()])\n",
    "node_vectors = np.array(node_vectors)\n",
    "node_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An edge vector will be a function of the two node vectors that define the edge. We have different options available for such a function. We define several below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_hadamard(u, v):\n",
    "    return u * v\n",
    "\n",
    "\n",
    "def operator_l1(u, v):\n",
    "    return np.abs(u - v)\n",
    "\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def operator_avg(u, v):\n",
    "    return (u + v) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_vectors(edges, node_vectors, op=operator_hadamard):\n",
    "    edge_vectors = []\n",
    "    for source, target in zip(edges[0], edges[1]):\n",
    "        edge_vectors.append(op(node_vectors[source], node_vectors[target]))\n",
    "    edge_vectors = torch.tensor(edge_vectors)\n",
    "    return edge_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_vectors = get_edge_vectors(edges, node_vectors, op=operator_hadamard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_vectors.shape, len(edge_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to split our edge data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    edge_vectors_train, \n",
    "    edge_vectors_test, \n",
    "    edge_labels_train, \n",
    "    edge_labels_test\n",
    ") = train_test_split(edge_vectors, edge_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_vectors_train.shape, edge_vectors_test.shape, edge_labels_train.shape, edge_labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Random Forest to predict edges. Since we are training a binary classification model, we can evaluate its performance using accuracy but also AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=2, n_jobs=2, random_state=1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(edge_vectors_train, edge_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on train data: {rf.score(edge_vectors_train, edge_labels_train):.2}\")\n",
    "print(f\"Accuracy on test data : {rf.score(edge_vectors_test, edge_labels_test):.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels_train_pred_prob = rf.predict_proba(edge_vectors_train)[:, 1]\n",
    "edge_labels_test_pred_prob = rf.predict_proba(edge_vectors_test)[:, 1]\n",
    "print(f\"AUC on train data: {roc_auc_score(edge_labels_train, edge_labels_train_pred_prob):.2}\")\n",
    "print(f\"AUC on test data: {roc_auc_score(edge_labels_test, edge_labels_test_pred_prob):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels_test_pred = rf.predict(edge_vectors_test)\n",
    "fpr, tpr, _ = roc_curve(edge_labels_test, edge_labels_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curve (test data)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "\\[1\\] Try different operators for combining node embeddings to generate edge embeddings. How does performance change?\n",
    "\n",
    "\\[2\\] Consider sampling negative examples using the *local* approach mentioned in the presentation. How does performance change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRL Course",
   "language": "python",
   "name": "grl-course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
