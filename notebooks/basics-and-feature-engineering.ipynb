{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic definitions. Centrality Measures. Feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we introduce some basics of networkx library. More in-depth tutorial can be found [here](https://networkx.github.io/documentation/stable/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networkx basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty graph\n",
    "G = nx.Graph(name=\"Friendship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding one node\n",
    "G.add_node(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding several nodes as a list\n",
    "G.add_nodes_from([\"Liz\", \"Katie\", \"Sam\", \"Bob\", \"Tom\", \"Mary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an edge\n",
    "G.add_edge(\"Liz\",\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a list of edges:\n",
    "G.add_edges_from([(\"Liz\",\"John\"),(\"Katie\",\"Sam\"), (\"Bob\",\"Katie\"), (\"Katie\", \"Tom\"), (\"Liz\", \"Tom\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.nodes())\n",
    "print(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Question: what will happen if we add edges with the nodes that do not exist in the graph?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from([(\"A\",\"B\"), (1,2), (\"Bob\",\"Santa\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing an edge\n",
    "print(G.edges())\n",
    "G.remove_edge(1,2)\n",
    "print(G.edges()) # edge is removed\n",
    "print(G.nodes()) # but nodes are still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabeling nodes\n",
    "correction = {\"A\":\"Tim\", \"B\":\"Ben\"}\n",
    "\n",
    "H = nx.relabel_nodes(G, correction)\n",
    "nx.draw(H, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the graph to directed\n",
    "H_directed = H.to_directed()\n",
    "print(H_directed)\n",
    "nx.draw(H_directed, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connected components and isolates\n",
    "nx.number_connected_components(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.connected_components(H) # displays an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.connected_components(H)) # transform it to the list for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.isolates(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating graph from diffrent formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.array([[0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 0]])\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "print(\"Nodes: \")\n",
    "print(G.nodes())\n",
    "print(\"Edges: \")\n",
    "print(G.edges())\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list = {'A':['B','C','D', 'F', 'G'], \n",
    "                  'B': ['A', 'G'], \n",
    "                  'D': ['A', 'C'], \n",
    "                  'G': ['C','F']\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_dict_of_lists(adjacency_list, create_using=nx.DiGraph())\n",
    "print(G)\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Network of coappearances of characters in the Game of Thrones series, by George R. R. Martin, and in particular coappearances in the book \"A Storm of Swords.\" Nodes are unique characters, and edges are weighted by the number of times the two characters' names appeared within 15 words of each other in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donwload data from http://www.macalester.edu/~abeverid/data/stormofswords.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/GoT\"\n",
    "data_location = os.path.expanduser(os.path.join(data_dir, \"stormofswords.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(dt, source='Source', target='Target')\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated graph drawing\n",
    "\n",
    "plt.figure(figsize=(10,8)) # change the size of the figure\n",
    "pos = nx.fruchterman_reingold_layout(G, iterations=10) # specify layout\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=600, node_color='#ec008c', edgecolors='grey', alpha=0.3)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos,\n",
    "                       width=1, alpha=0.5, edge_color='grey')\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality_sorted = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality_sorted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = [v * 3000 for v in degree_centrality.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8)) # change the size of the figure\n",
    "pos = nx.kamada_kawai_layout(G) # specify layout\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color='#ec008c', edgecolors='grey', alpha=0.3)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos,\n",
    "                       width=1, alpha=0.5, edge_color='grey')\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = nx.betweenness_centrality(G)\n",
    "betweenness_sorted = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "betweenness_sorted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(G)\n",
    "closeness_sorted = sorted(closeness.items(), key=lambda x: x[1], reverse=True)\n",
    "closeness_sorted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector = nx.eigenvector_centrality(G)\n",
    "eigenvector_sorted = sorted(eigenvector.items(), key=lambda x: x[1], reverse=True)\n",
    "eigenvector_sorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is the citation network Cora.\n",
    "\n",
    "It can be downloaded by clicking [here](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz)\n",
    "\n",
    "The following is the description of the dataset from the publisher,\n",
    "\n",
    "> The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words. The README file in the dataset provides more details. \n",
    "\n",
    "Download and unzip the cora.tgz file to a location on your computer. \n",
    "\n",
    "We assume that the dataset is stored in the directory\n",
    "\n",
    "`../data/cora/`\n",
    "\n",
    "where the files `cora.cites` and `cora.content` can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/cora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edgelist data\n",
    "edgelist = pd.read_table(os.path.join(data_dir, \"cora.cites\"), header=None, names=[\"source\", \"target\"])\n",
    "edgelist[\"label\"] = \"cites\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nx = nx.from_pandas_edgelist(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing cora data attributes\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  ['paper_id'] + feature_names + [\"subject\"]\n",
    "node_data = pd.read_table(os.path.join(data_dir, \"cora.content\"), header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = { row.tolist()[0]: row.tolist()[-1] for _, row in node_data.iterrows()}\n",
    "nx.set_node_attributes(g_nx, values, 'subject') # assig attributes to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(g_nx.nodes(data=True))[:5] # print first few lines of the nodes with their attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.number_connected_components(g_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the largest connected component\n",
    "g_nx_ccs = (g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx))\n",
    "g_nx = max(g_nx_ccs, key=len)\n",
    "print(\"Largest subgraph statistics: {} nodes, {} edges\".format(\n",
    "    g_nx.number_of_nodes(), g_nx.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subgraph of papers that belong to a class: \"Rule learning\" and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nodes = [n for n,v in g_nx.nodes(data=True) if v['subject'] == 'Rule_Learning']\n",
    "subgraph_rl = g_nx.subgraph(selected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subgraph_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8)) # change the size of the figure\n",
    "pos = nx.fruchterman_reingold_layout(subgraph_rl, iterations=10) # specify layout\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(subgraph_rl, pos, node_size=800, node_color='lightblue', edgecolors='grey')\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(subgraph_rl, pos,\n",
    "                       width=1, alpha=0.5, edge_color='grey')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: output now subgraph for any other paper subject. Optional: try to change the size of the nodes based on a degree or any other metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a paper's subject\n",
    "\n",
    "We develop a Logistic regression classifier for predicting a paper's subject given the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the node data that is in the largest connected component\n",
    "node_data_gcc = node_data[node_data.paper_id.isin(list(g_nx.nodes))]\n",
    "print(node_data_gcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data_gcc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X are the features that are calcualted from the graph\n",
    "X = node_data_gcc.drop(['paper_id','subject'], axis=1).values \n",
    "# y holds the corresponding target values\n",
    "y = node_data_gcc['subject'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "We split the data into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=140, test_size=None, random_state=42)\n",
    "print(\"Array shapes:\\n X_train = {}\\n y_train = {}\\n X_test = {}\\n y_test = {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Training\n",
    "\n",
    "We train a Logistic Regression classifier on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(Cs=10, \n",
    "                           cv=5, \n",
    "                           verbose=False,\n",
    "                           multi_class='multinomial', \n",
    "                           max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score on X_train {}\".format(clf.score(X_train, y_train)))\n",
    "print(\"score on X_test {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(y_pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Question: What class is the easiest/hardest to predict?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let us now develop a classification model that utilises graph-based features. We will train and evaluate a\n",
    "Logistic regression model with centrality measures as the input node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality measures\n",
    "nx.set_node_attributes(g_nx, nx.degree_centrality(g_nx), 'degree_centrality')\n",
    "nx.set_node_attributes(g_nx, nx.betweenness_centrality(g_nx), 'betweenness')\n",
    "nx.set_node_attributes(g_nx, nx.closeness_centrality(g_nx), 'closeness')\n",
    "nx.set_node_attributes(g_nx, nx.eigenvector_centrality(g_nx), 'eigenvector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(g_nx.nodes(data=True))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_features = pd.DataFrame.from_dict(dict(g_nx.nodes(data=True)), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X are the features that are calcualted from the graph\n",
    "X = graph_features.drop(['subject'], axis=1).values \n",
    "# y holds the corresponding target values\n",
    "y = graph_features['subject'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "We split the data into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=140, test_size=None, random_state=42)\n",
    "print(\"Array shapes:\\n X_train = {}\\n y_train = {}\\n X_test = {}\\n y_test = {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Training\n",
    "\n",
    "We train a Logistic Regression classifier on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(Cs=10, \n",
    "                           cv=5, \n",
    "                           verbose=False,\n",
    "                           multi_class='multinomial', \n",
    "                           max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score on X_train {}\".format(clf.score(X_train, y_train)))\n",
    "print(\"score on X_test {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(y_pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Combine the node attribute vectors with the centrality features and train a classifier. How does it perform in comparison to using only the node attribute vectors or the centrality measure as the data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grl-course-env",
   "language": "python",
   "name": "grl-course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
